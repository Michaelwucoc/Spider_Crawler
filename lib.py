import os

# Automatically help you create a folder for the project you crawl

def create_project_dir(directory):
    if not os.path.exists(directory):
        print("Creating directory: " + directory)
        os.makedirs(directory)

def create_data_files(project_name, base_url):
    queue = project_name + "/queue.txt"
    crawled = project_name + "/crawled.txt"  # Create the directory for queue and crawled links
    if not os.path.isfile(queue):
        write_file(queue, base_url)  # Create the files but with its first queued link to crawl
    if not os.path.isfile(crawled):
        write_file(crawled, "")

def write_file(path, data):
    with open(path, 'w') as f:  # switch to write mode
        f.write(data)

def append_to_file(path, data):
    with open(path, "a") as file:
        file.write(data + "\n")  # Corrected newline character

def delete_file_contents(path):
    with open(path, "w") as file:  # Open the file in write mode to clear its contents
        pass  # Effectively clears the file

def file_to_set(file_name):
    result = set()
    try:
        with open(file_name, 'r') as file:
            for line in file:
                result.add(line.strip())
    except FileNotFoundError:
        print("Error: File not found")
    except Exception as e:
        print("Error reading file:", str(e))
    return result

def set_to_file(links, file):  # links represents set, file represents file
    delete_file_contents(file)  # Clear file contents
    for link in links:
        append_to_file(file, link)

def create_autogenerated_dir(directory):
    auto_gen_dir = directory + "/AutoGenerated"
    if not os.path.exists(auto_gen_dir):
        print("Creating AutoGenerated directory: " + auto_gen_dir)
        os.makedirs(auto_gen_dir)
    return auto_gen_dir